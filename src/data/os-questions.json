[
  {
    "id": 1,
    "question": "Which of the following conditions is NOT necessary for a deadlock to occur?",
    "options": [
      {
        "key": "A",
        "text": "Mutual Exclusion"
      },
      {
        "key": "B",
        "text": "Hold and Wait"
      },
      {
        "key": "C",
        "text": "No Preemption"
      },
      {
        "key": "D",
        "text": "Starvation"
      }
    ],
    "answer": "D",
    "explanation": "Starvation is a scheduling issue where a process waits indefinitely, but it is not a prerequisite for a deadlock. For a deadlock to occur, four specific conditions must hold simultaneously: Mutual Exclusion, Hold and Wait, No Preemption, and Circular Wait."
  },
  {
    "id": 2,
    "question": "In a paging system, if the page size is increased, what is the most likely effect on fragmentation?",
    "options": [
      {
        "key": "A",
        "text": "Internal fragmentation increases"
      },
      {
        "key": "B",
        "text": "External fragmentation increases"
      },
      {
        "key": "C",
        "text": "Internal fragmentation decreases"
      },
      {
        "key": "D",
        "text": "No change in fragmentation"
      }
    ],
    "answer": "A",
    "explanation": "When page size increases, the average unused space in the last page of a process (which is rarely perfectly filled) also increases. This wasted space within an allocated block is called internal fragmentation."
  },
  {
    "id": 3,
    "question": "Which disk scheduling algorithm is most likely to cause starvation for requests far from the current head position?",
    "options": [
      {
        "key": "A",
        "text": "FCFS"
      },
      {
        "key": "B",
        "text": "SSTF"
      },
      {
        "key": "C",
        "text": "SCAN"
      },
      {
        "key": "D",
        "text": "C-SCAN"
      }
    ],
    "answer": "B",
    "explanation": "Shortest Seek Time First prioritizes requests closest to the current disk head position. If a continuous stream of requests arrives near the current position, requests at the far ends of the disk may wait indefinitely (starvation)."
  },
  {
    "id": 4,
    "question": "A system is in a safe state if:",
    "options": [
      {
        "key": "A",
        "text": "There are no deadlocks currently."
      },
      {
        "key": "B",
        "text": "There is at least one process that can complete."
      },
      {
        "key": "C",
        "text": "There exists a safe sequence of all processes."
      },
      {
        "key": "D",
        "text": "The resource allocation graph has no cycles."
      }
    ],
    "answer": "C",
    "explanation": "A system is in a safe state only if the OS can allocate resources to each process in some specific order (a safe sequence) such that every process can eventually obtain its maximum needed resources and terminate."
  },
  {
    "id": 5,
    "question": "Which component of the disk structure is responsible for the time it takes for the desired sector to rotate under the disk head?",
    "options": [
      {
        "key": "A",
        "text": "Seek Time"
      },
      {
        "key": "B",
        "text": "Rotational Latency"
      },
      {
        "key": "C",
        "text": "Transfer Rate"
      },
      {
        "key": "D",
        "text": "Access Time"
      }
    ],
    "answer": "B",
    "explanation": "Disk access time is composed of Seek Time (moving the arm), Rotational Latency (waiting for the sector to spin under the head), and Transfer Time. Latency specifically refers to the rotation delay."
  },
  {
    "id": 6,
    "question": "In the context of the Critical Section Problem, \"Progress\" means:",
    "options": [
      {
        "key": "A",
        "text": "No process waits forever."
      },
      {
        "key": "B",
        "text": "If no process is executing in its critical section, the selection of the next process cannot be postponed indefinitely."
      },
      {
        "key": "C",
        "text": "Processes must enter the critical section in a specific order."
      },
      {
        "key": "D",
        "text": "The CPU is never idle."
      }
    ],
    "answer": "B",
    "explanation": "The \"Progress\" requirement ensures that if the critical section is free and processes wish to enter, the decision of who enters next cannot be delayed forever; the system must make a decision and proceed."
  },
  {
    "id": 7,
    "question": "Thrashing occurs when:",
    "options": [
      {
        "key": "A",
        "text": "The CPU is utilized 100%."
      },
      {
        "key": "B",
        "text": "The sum of the size of the working sets exceeds the total number of available frames."
      },
      {
        "key": "C",
        "text": "The page fault rate is very low."
      },
      {
        "key": "D",
        "text": "Processes have too many frames allocated."
      }
    ],
    "answer": "B",
    "explanation": "Thrashing happens when the OS spends more time swapping pages in and out than executing instructions. This occurs when the total memory required by active processes (working sets) is larger than physical RAM."
  },
  {
    "id": 8,
    "question": "Which mechanism is used to determine where in memory a process should be loaded (e.g., First-fit, Best-fit)?",
    "options": [
      {
        "key": "A",
        "text": "Address Binding"
      },
      {
        "key": "B",
        "text": "Contiguous Allocation"
      },
      {
        "key": "C",
        "text": "Paging"
      },
      {
        "key": "D",
        "text": "Dynamic Linking"
      }
    ],
    "answer": "B",
    "explanation": "First-fit, Best-fit, and Worst-fit are strategies used in Contiguous Memory Allocation to find a suitable \"hole\" or free block in main memory to place a process."
  },
  {
    "id": 9,
    "question": "Belady’s Anomaly is observed in which page replacement algorithm?",
    "options": [
      {
        "key": "A",
        "text": "LRU"
      },
      {
        "key": "B",
        "text": "Optimal"
      },
      {
        "key": "C",
        "text": "FIFO"
      },
      {
        "key": "D",
        "text": "LFU"
      }
    ],
    "answer": "C",
    "explanation": "Belady’s Anomaly is a phenomenon where increasing the number of page frames results in an increase in the number of page faults. This is specific to the First-In-First-Out (FIFO) replacement algorithm."
  },
  {
    "id": 10,
    "question": "The Banker’s Algorithm is used for:",
    "options": [
      {
        "key": "A",
        "text": "Deadlock Prevention"
      },
      {
        "key": "B",
        "text": "Deadlock Avoidance"
      },
      {
        "key": "C",
        "text": "Deadlock Detection"
      },
      {
        "key": "D",
        "text": "Deadlock Recovery"
      }
    ],
    "answer": "B",
    "explanation": "The Banker’s Algorithm is a Deadlock Avoidance strategy. It simulates resource allocation for every request to check if granting it would leave the system in a \"Safe State.\" If not, the request is denied or delayed."
  },
  {
    "id": 11,
    "question": "In Segmentation, the logical address consists of:",
    "options": [
      {
        "key": "A",
        "text": "Page number and Offset"
      },
      {
        "key": "B",
        "text": "Frame number and Offset"
      },
      {
        "key": "C",
        "text": "Segment number and Offset"
      },
      {
        "key": "D",
        "text": "Segment number and Page number"
      }
    ],
    "answer": "C",
    "explanation": "In segmentation, the user views memory as a collection of segments. The logical address is a tuple <segment-number, offset>, where the segment number indexes into the Segment Table to find the base address."
  },
  {
    "id": 12,
    "question": "Which system call is typically used by a parent process to wait for the termination of a child process?",
    "options": [
      {
        "key": "A",
        "text": "fork()"
      },
      {
        "key": "B",
        "text": "exec()"
      },
      {
        "key": "C",
        "text": "wait()"
      },
      {
        "key": "D",
        "text": "signal()"
      }
    ],
    "answer": "C",
    "explanation": "The wait() system call suspends the execution of the calling process (parent) until one of its children terminates. It allows the parent to synchronize with the child's completion and retrieve its exit status."
  },
  {
    "id": 13,
    "question": "In the Access Matrix model of protection, the rows typically represent ______ and the columns represent ______.",
    "options": [
      {
        "key": "A",
        "text": "Objects, Domains"
      },
      {
        "key": "B",
        "text": "Domains, Objects"
      },
      {
        "key": "C",
        "text": "Files, Users"
      },
      {
        "key": "D",
        "text": "Processes, Resources"
      }
    ],
    "answer": "B",
    "explanation": "In the Access Matrix model, rows represent Domains (users or processes with specific rights) and columns represent Objects (resources or files). The intersection defines the access rights a domain has over an object."
  },
  {
    "id": 14,
    "question": "Which CPU scheduling algorithm allows a process to move between different queues based on its behavior (e.g., CPU bursts)?",
    "options": [
      {
        "key": "A",
        "text": "Round Robin"
      },
      {
        "key": "B",
        "text": "FCFS"
      },
      {
        "key": "C",
        "text": "Multilevel Feedback Queue"
      },
      {
        "key": "D",
        "text": "Priority Scheduling"
      }
    ],
    "answer": "C",
    "explanation": "This algorithm allows processes to move between queues. If a process uses too much CPU time, it is moved to a lower-priority queue; if it waits too long (aging), it may be moved to a higher-priority queue."
  },
  {
    "id": 15,
    "question": "TLB (Translation Lookaside Buffer) is used to:",
    "options": [
      {
        "key": "A",
        "text": "Store the entire page table."
      },
      {
        "key": "B",
        "text": "Speed up logical-to-physical address translation."
      },
      {
        "key": "C",
        "text": "Handle page faults."
      },
      {
        "key": "D",
        "text": "Store frequently accessed disk sectors."
      }
    ],
    "answer": "B",
    "explanation": "The TLB is a fast, associative hardware cache inside the MMU. It stores recent virtual-to-physical address translations to avoid the performance penalty of accessing the page table in main memory for every instruction."
  },
  {
    "id": 16,
    "question": "If a system uses C-SCAN disk scheduling, how does the disk head move?",
    "options": [
      {
        "key": "A",
        "text": "It moves back and forth, servicing requests in both directions."
      },
      {
        "key": "B",
        "text": "It moves in one direction servicing requests, then jumps back to the beginning without servicing requests on the return."
      },
      {
        "key": "C",
        "text": "It always moves to the closest request."
      },
      {
        "key": "D",
        "text": "It services requests in the order of arrival."
      }
    ],
    "answer": "B",
    "explanation": "Circular SCAN (C-SCAN) treats the cylinders as a circular list. It services requests in only one direction to ensure a more uniform wait time, then essentially \"rewinds\" to the start immediately without servicing on the return trip."
  },
  {
    "id": 17,
    "question": "Which of the following is true regarding User-level threads vs Kernel-level threads?",
    "options": [
      {
        "key": "A",
        "text": "User-level threads are slower to create."
      },
      {
        "key": "B",
        "text": "If a user-level thread performs a blocking system call, the entire process will block."
      },
      {
        "key": "C",
        "text": "The kernel is aware of all user-level threads."
      },
      {
        "key": "D",
        "text": "User-level threads require hardware support."
      }
    ],
    "answer": "B",
    "explanation": "Since the OS kernel is unaware of user-level threads, it views the process as a single thread of execution. If that single kernel-thread blocks (e.g., waiting for I/O), the OS blocks the whole process, stopping all other user threads within it."
  },
  {
    "id": 18,
    "question": "What is the main advantage of Dynamic Loading?",
    "options": [
      {
        "key": "A",
        "text": "A routine is not loaded until it is called, saving memory space."
      },
      {
        "key": "B",
        "text": "It allows multiple processes to share code."
      },
      {
        "key": "C",
        "text": "It prevents internal fragmentation."
      },
      {
        "key": "D",
        "text": "It eliminates the need for relocation."
      }
    ],
    "answer": "A",
    "explanation": "Dynamic loading delays the loading of a subroutine until it is explicitly called during execution. This improves memory utilization because unused routines are never loaded into RAM."
  },
  {
    "id": 19,
    "question": "In a Resource Allocation Graph, a cycle indicates a deadlock only if:",
    "options": [
      {
        "key": "A",
        "text": "There is a single instance of each resource type."
      },
      {
        "key": "B",
        "text": "There are multiple instances of each resource type."
      },
      {
        "key": "C",
        "text": "There is a single instance of each resource type (necessary and sufficient)."
      },
      {
        "key": "D",
        "text": "The graph is disconnected."
      }
    ],
    "answer": "A",
    "explanation": "If every resource type has only one instance, a cycle in the Resource Allocation Graph implies a circular wait, which is both necessary and sufficient for a deadlock. If multiple instances exist, a cycle implies a deadlock is only possible."
  },
  {
    "id": 20,
    "question": "Which page replacement algorithm usually provides the minimum page fault rate?",
    "options": [
      {
        "key": "A",
        "text": "FIFO"
      },
      {
        "key": "B",
        "text": "LRU"
      },
      {
        "key": "C",
        "text": "Optimal"
      },
      {
        "key": "D",
        "text": "Counting-based"
      }
    ],
    "answer": "C",
    "explanation": "The Optimal Page Replacement algorithm (OPT) replaces the page that will not be used for the longest period of time. It is a theoretical benchmark that guarantees the lowest possible page fault rate but requires future knowledge."
  },
  {
    "id": 21,
    "question": "Context Switching is:",
    "options": [
      {
        "key": "A",
        "text": "Switching the CPU from user mode to kernel mode."
      },
      {
        "key": "B",
        "text": "Storing the state of the current process and loading the saved state of a new process."
      },
      {
        "key": "C",
        "text": "Swapping a process from memory to disk."
      },
      {
        "key": "D",
        "text": "Changing the priority of a process."
      }
    ],
    "answer": "B",
    "explanation": "Context Switching is the overhead process of saving the Process Control Block (PCB) of the currently running process and restoring the PCB of the next process to be executed."
  },
  {
    "id": 22,
    "question": "The \"Working Set\" model is based on the assumption of:",
    "options": [
      {
        "key": "A",
        "text": "Global replacement."
      },
      {
        "key": "B",
        "text": "Random access patterns."
      },
      {
        "key": "C",
        "text": "Locality of reference."
      },
      {
        "key": "D",
        "text": "Pre-paging."
      }
    ],
    "answer": "C",
    "explanation": "The Working Set model relies on the principle of Locality of Reference, which states that processes tend to access a specific set of pages (a \"locality\") frequently during a specific time window."
  },
  {
    "id": 23,
    "question": "Which method of handling deadlocks involves granting resources only if the allocation leaves the system in a safe state?",
    "options": [
      {
        "key": "A",
        "text": "Prevention"
      },
      {
        "key": "B",
        "text": "Avoidance"
      },
      {
        "key": "C",
        "text": "Detection"
      },
      {
        "key": "D",
        "text": "Recovery"
      }
    ],
    "answer": "B",
    "explanation": "Deadlock Avoidance checks the system state before allocation. It only grants a resource request if the resulting state is \"safe\" (i.e., deadlock is mathematically impossible), preventing the system from entering an unsafe state."
  },
  {
    "id": 24,
    "question": "Internal Fragmentation is a common issue in:",
    "options": [
      {
        "key": "A",
        "text": "Fixed Partitioning and Paging"
      },
      {
        "key": "B",
        "text": "Dynamic Partitioning and Segmentation"
      },
      {
        "key": "C",
        "text": "Segmentation only"
      },
      {
        "key": "D",
        "text": "Demand Paging only"
      }
    ],
    "answer": "A",
    "explanation": "Internal fragmentation occurs when memory is allocated in fixed-sized blocks (like pages or fixed partitions). If a process needs less space than the block size, the remaining space inside that block is wasted."
  },
  {
    "id": 25,
    "question": "The problem of starvation in priority scheduling can be resolved by:",
    "options": [
      {
        "key": "A",
        "text": "Context Switching"
      },
      {
        "key": "B",
        "text": "Aging"
      },
      {
        "key": "C",
        "text": "Swapping"
      },
      {
        "key": "D",
        "text": "Round Robin"
      }
    ],
    "answer": "B",
    "explanation": "Aging is a technique where the priority of a process is gradually increased the longer it waits in the system. This prevents low-priority processes from being starved indefinitely by high-priority ones."
  },
  {
    "id": 26,
    "question": "Which file access method is best suited for database applications where arbitrary records need to be accessed quickly?",
    "options": [
      {
        "key": "A",
        "text": "Sequential Access"
      },
      {
        "key": "B",
        "text": "Direct/Random Access"
      },
      {
        "key": "C",
        "text": "Indexed Sequential Access"
      },
      {
        "key": "D",
        "text": "Contiguous Access"
      }
    ],
    "answer": "B",
    "explanation": "Direct access allows a program to jump to any logical record in a file immediately (like a CD track). This is essential for databases where users need to retrieve specific records without reading everything preceding them."
  },
  {
    "id": 27,
    "question": "If the time quantum in Round Robin scheduling is extremely large, the algorithm degenerates into:",
    "options": [
      {
        "key": "A",
        "text": "FCFS"
      },
      {
        "key": "B",
        "text": "SJF"
      },
      {
        "key": "C",
        "text": "Priority Scheduling"
      },
      {
        "key": "D",
        "text": "Multilevel Queue"
      }
    ],
    "answer": "A",
    "explanation": "In Round Robin, if the time quantum is infinitely large, the first process will finish its entire CPU burst before the timer interrupts. This behavior is identical to First-Come, First-Served (FCFS)."
  },
  {
    "id": 28,
    "question": "Compaction is a solution for:",
    "options": [
      {
        "key": "A",
        "text": "Internal Fragmentation"
      },
      {
        "key": "B",
        "text": "External Fragmentation"
      },
      {
        "key": "C",
        "text": "Thrashing"
      },
      {
        "key": "D",
        "text": "Deadlocks"
      }
    ],
    "answer": "B",
    "explanation": "Compaction (or defragmentation) shuffles memory contents to place all free memory together in one large block. This resolves external fragmentation, where total free memory is sufficient but scattered in small chunks."
  },
  {
    "id": 29,
    "question": "A semaphore that can take any non-negative integer value is called a:",
    "options": [
      {
        "key": "A",
        "text": "Binary Semaphore"
      },
      {
        "key": "B",
        "text": "Mutex"
      },
      {
        "key": "C",
        "text": "Counting Semaphore"
      },
      {
        "key": "D",
        "text": "Spinlock"
      }
    ],
    "answer": "C",
    "explanation": "A counting semaphore is a synchronization variable that can value range over an unrestricted domain (non-negative integers). It is typically used to control access to a resource that has multiple instances."
  },
  {
    "id": 30,
    "question": "In Demand Paging, a page fault occurs when:",
    "options": [
      {
        "key": "A",
        "text": "The page is in memory but locked."
      },
      {
        "key": "B",
        "text": "The requested page is not currently in memory."
      },
      {
        "key": "C",
        "text": "The process tries to access a restricted memory area."
      },
      {
        "key": "D",
        "text": "The TLB is full."
      }
    ],
    "answer": "B",
    "explanation": "A page fault is a hardware trap raised by the MMU when a program accesses a logical page that is marked \"invalid\" in the page table because it has not yet been loaded into physical RAM."
  },
  {
    "id": 31,
    "question": "Logical address space is generated by:",
    "options": [
      {
        "key": "A",
        "text": "The CPU"
      },
      {
        "key": "B",
        "text": "The MMU"
      },
      {
        "key": "C",
        "text": "The OS kernel"
      },
      {
        "key": "D",
        "text": "The Disk Controller"
      }
    ],
    "answer": "A",
    "explanation": "The CPU generates logical (virtual) addresses while executing a program. The Memory Management Unit (MMU) is the hardware component that translates these logical addresses into physical addresses."
  },
  {
    "id": 32,
    "question": "Which of the following disk scheduling algorithms yields the lowest variance in response time?",
    "options": [
      {
        "key": "A",
        "text": "SSTF"
      },
      {
        "key": "B",
        "text": "FCFS"
      },
      {
        "key": "C",
        "text": "C-SCAN"
      },
      {
        "key": "D",
        "text": "SCAN"
      }
    ],
    "answer": "C",
    "explanation": "C-SCAN provides a more uniform wait time compared to SCAN or SSTF. By servicing requests in only one direction, it prevents the bias against requests located at the far ends of the disk (reducing variance)."
  },
  {
    "id": 33,
    "question": "To prevent a deadlock by denying the \"Hold and Wait\" condition, a system could:",
    "options": [
      {
        "key": "A",
        "text": "Preempt resources from a holding process."
      },
      {
        "key": "B",
        "text": "Require a process to request and be allocated all its resources before execution begins."
      },
      {
        "key": "C",
        "text": "Order resources numerically."
      },
      {
        "key": "D",
        "text": "Use the Banker's Algorithm."
      }
    ],
    "answer": "B",
    "explanation": "This strategy invalidates the \"Hold and Wait\" condition. If a process must grab all resources at the start, it never holds some resources while waiting for others, effectively preventing deadlock."
  },
  {
    "id": 34,
    "question": "The Dirty Bit in a page table entry indicates:",
    "options": [
      {
        "key": "A",
        "text": "The page is invalid."
      },
      {
        "key": "B",
        "text": "The page is read-only."
      },
      {
        "key": "C",
        "text": "The page has been modified since it was loaded into memory."
      },
      {
        "key": "D",
        "text": "The page is currently in the TLB."
      }
    ],
    "answer": "C",
    "explanation": "The Dirty Bit (or modify bit) is set by hardware whenever a page is written to. If the bit is set, the page must be written back to the disk (swapped out) before the frame can be reused; otherwise, the changes are lost."
  },
  {
    "id": 35,
    "question": "Which structure helps resolve the issue of very large page tables in systems with large logical address spaces?",
    "options": [
      {
        "key": "A",
        "text": "TLB"
      },
      {
        "key": "B",
        "text": "Multi-level Paging (Hierarchical Paging)"
      },
      {
        "key": "C",
        "text": "Inverted Page Table"
      },
      {
        "key": "D",
        "text": "Hashed Page Table"
      }
    ],
    "answer": "B",
    "explanation": "Systems with large logical address spaces would require massive page tables that consume too much contiguous memory. Multi-level paging breaks the page table into smaller pieces (paging the page table), so only parts of it need to be in memory."
  },
  {
    "id": 36,
    "question": "In the context of disk management, boot block stores:",
    "options": [
      {
        "key": "A",
        "text": "The file system structure."
      },
      {
        "key": "B",
        "text": "The bootstrap loader program."
      },
      {
        "key": "C",
        "text": "Bad blocks info."
      },
      {
        "key": "D",
        "text": "The operating system kernel."
      }
    ],
    "answer": "B",
    "explanation": "The boot block (usually the first block of the disk) contains the initial bootstrap program. The hardware loads this code on startup, which then locates and loads the full Operating System kernel."
  },
  {
    "id": 37,
    "question": "A system has 3 processes sharing 4 resources. If each process needs a maximum of 2 units, deadlock is:",
    "options": [
      {
        "key": "A",
        "text": "Inevitable."
      },
      {
        "key": "B",
        "text": "Possible."
      },
      {
        "key": "C",
        "text": "Impossible."
      }
    ],
    "answer": "C",
    "explanation": "Deadlock occurs if all processes are holding resources and waiting for more. With 3 processes and 4 resources, even if every process holds 1 resource (Total 3), there is 1 resource left. One process can take it, reach its max of 2, finish, and return the resources."
  },
  {
    "id": 38,
    "question": "Inverted Page Tables map:",
    "options": [
      {
        "key": "A",
        "text": "Logical addresses to physical addresses directly."
      },
      {
        "key": "B",
        "text": "Logical pages to physical frames per process."
      },
      {
        "key": "C",
        "text": "Physical frame numbers to logical page numbers (PID + Page#)."
      },
      {
        "key": "D",
        "text": "Disk blocks to memory frames."
      }
    ],
    "answer": "C",
    "explanation": "Standard page tables map Page to Frame. Inverted Page Tables map Frame to Page (and Process ID). There is only one entry per physical frame, which saves memory but necessitates searching the table."
  },
  {
    "id": 39,
    "question": "The Wait-for graph is a deadlock detection method used for systems with:",
    "options": [
      {
        "key": "A",
        "text": "Multiple instances of each resource type."
      },
      {
        "key": "B",
        "text": "Single instance of each resource type."
      },
      {
        "key": "C",
        "text": "Preemptible resources only."
      },
      {
        "key": "D",
        "text": "Infinite resources."
      }
    ],
    "answer": "B",
    "explanation": "A Wait-for graph is a collapsed version of the Resource Allocation Graph. It is only applicable for deadlock detection when there is a single instance of each resource type; a cycle in this graph confirms a deadlock."
  },
  {
    "id": 40,
    "question": "If Effective Access Time = (1-p) x ma + p x (page fault time), what does 'p' represent?",
    "options": [
      {
        "key": "A",
        "text": "Probability of a TLB hit."
      },
      {
        "key": "B",
        "text": "Process priority."
      },
      {
        "key": "C",
        "text": "Page fault rate."
      },
      {
        "key": "D",
        "text": "CPU utilization."
      }
    ],
    "answer": "C",
    "explanation": "The variable p represents the probability that a memory access results in a page fault. The formula calculates the weighted average of memory access time based on how often faults occur."
  },
  {
    "id": 41,
    "question": "In Linked Allocation of files:",
    "options": [
      {
        "key": "A",
        "text": "Random access is extremely fast."
      },
      {
        "key": "B",
        "text": "There is no external fragmentation."
      },
      {
        "key": "C",
        "text": "Seeking to the middle of a file is efficient."
      },
      {
        "key": "D",
        "text": "All pointers are stored in a central index block."
      }
    ],
    "answer": "B",
    "explanation": "In Linked Allocation, files are stored as a linked list of blocks, which can be scattered anywhere on the disk. This eliminates external fragmentation because any free block can be used to extend the file."
  },
  {
    "id": 42,
    "question": "What is the primary benefit of using Overlays?",
    "options": [
      {
        "key": "A",
        "text": "Faster context switching."
      },
      {
        "key": "B",
        "text": "Running a process that is larger than the available physical memory."
      },
      {
        "key": "C",
        "text": "Reducing internal fragmentation."
      },
      {
        "key": "D",
        "text": "Simplifying address binding."
      }
    ],
    "answer": "B",
    "explanation": "Overlays allow a process to run even if it is larger than physical memory by keeping only the instructions needed at that moment in memory. When a different phase of the program is needed, it overwrites (overlays) the previous one."
  },
  {
    "id": 43,
    "question": "Which deadlock recovery method involves rolling back a process to a safe state?",
    "options": [
      {
        "key": "A",
        "text": "Process Termination"
      },
      {
        "key": "B",
        "text": "Resource Preemption"
      },
      {
        "key": "C",
        "text": "Checkpointing and Rollback"
      },
      {
        "key": "D",
        "text": "Starvation"
      }
    ],
    "answer": "C",
    "explanation": "Deadlock recovery often involves rolling back a process. To do this, the system periodically saves the state (checkpoint). If a deadlock is detected, the process is reset to a previous safe checkpoint rather than being killed entirely."
  },
  {
    "id": 44,
    "question": "Circular Wait can be prevented by:",
    "options": [
      {
        "key": "A",
        "text": "Using semaphores."
      },
      {
        "key": "B",
        "text": "Imposing a total ordering of all resource types."
      },
      {
        "key": "C",
        "text": "Using time-outs."
      },
      {
        "key": "D",
        "text": "Using counting semaphores."
      }
    ],
    "answer": "B",
    "explanation": "This prevents Circular Wait. If resources are numbered (1, 2, 3...) and processes can only request resources in increasing order, a cycle cannot form."
  },
  {
    "id": 45,
    "question": "In Paged Segmentation:",
    "options": [
      {
        "key": "A",
        "text": "The segment is divided into pages."
      },
      {
        "key": "B",
        "text": "The pages are divided into segments."
      },
      {
        "key": "C",
        "text": "Memory allocation is done by frames, avoiding external fragmentation."
      },
      {
        "key": "D",
        "text": "It eliminates internal fragmentation entirely."
      }
    ],
    "answer": "A",
    "explanation": "Paged Segmentation combines both schemes. The logical address space is segmented to support user view/protection, but the linear segments themselves are divided into pages to simplify physical memory management and avoid external fragmentation."
  },
  {
    "id": 46,
    "question": "Which disk scheduling algorithm performs better for systems with a heavy load?",
    "options": [
      {
        "key": "A",
        "text": "FCFS"
      },
      {
        "key": "B",
        "text": "SCAN / Elevator"
      },
      {
        "key": "C",
        "text": "Random"
      },
      {
        "key": "D",
        "text": "Prioritized"
      }
    ],
    "answer": "B",
    "explanation": "Under heavy load, FCFS performs poorly due to excessive arm movement. SCAN (Elevator algorithm) is more efficient because it sweeps across the disk servicing multiple requests in a single pass, maximizing throughput."
  },
  {
    "id": 47,
    "question": "The Access Matrix can be implemented using:",
    "options": [
      {
        "key": "A",
        "text": "Global Table"
      },
      {
        "key": "B",
        "text": "Access Control Lists (ACL) for objects"
      },
      {
        "key": "C",
        "text": "Capability Lists for domains"
      },
      {
        "key": "D",
        "text": "All of the above"
      }
    ],
    "answer": "D",
    "explanation": "The Access Matrix is an abstract model. It can be implemented physically using a Global Table (sparse), Access Control Lists (storing columns with objects), or Capability Lists (storing rows with domains)."
  },
  {
    "id": 48,
    "question": "When does Address Binding happen at Load Time?",
    "options": [
      {
        "key": "A",
        "text": "If the process can be moved during execution."
      },
      {
        "key": "B",
        "text": "If it is known at compile time where the process will reside."
      },
      {
        "key": "C",
        "text": "If the compiler generates relocatable code and the binding is done when the program is loaded into memory."
      },
      {
        "key": "D",
        "text": "During the execution of the machine code instruction."
      }
    ],
    "answer": "C",
    "explanation": "Load-time binding occurs when the compiler doesn't know the absolute address. It generates relocatable addresses (relative to 0), and the loader adds the starting address of the memory block when the program is loaded."
  },
  {
    "id": 49,
    "question": "SSTF (Shortest Seek Time First) is essentially a form of ______ scheduling.",
    "options": [
      {
        "key": "A",
        "text": "FIFO"
      },
      {
        "key": "B",
        "text": "Round Robin"
      },
      {
        "key": "C",
        "text": "SJF (Shortest Job First)"
      },
      {
        "key": "D",
        "text": "Priority"
      }
    ],
    "answer": "C",
    "explanation": "SSTF is the disk-scheduling equivalent of Shortest Job First CPU scheduling. By selecting the request with the minimum seek time (shortest \"job\"), it reduces average service time but risks starvation for \"long\" jobs."
  },
  {
    "id": 50,
    "question": "Global replacement in page replacement algorithms allows:",
    "options": [
      {
        "key": "A",
        "text": "A process to select a replacement frame from the set of all frames in the system."
      },
      {
        "key": "B",
        "text": "A process to select only from its own allocated frames."
      },
      {
        "key": "C",
        "text": "The OS to replace kernel pages only."
      },
      {
        "key": "D",
        "text": "Replacement only when memory is completely full."
      }
    ],
    "answer": "A",
    "explanation": "Global replacement allows a process to \"steal\" a frame from another process if it needs one. This improves system throughput but means a process's execution time can vary based on the behavior of other processes."
  },
  {
    "id": 51,
    "question": "Which of the following is an example of a Deadlock Prevention strategy?",
    "options": [
      {
        "key": "A",
        "text": "Banker's Algorithm"
      },
      {
        "key": "B",
        "text": "Wait-For Graph"
      },
      {
        "key": "C",
        "text": "Spooling everything (to avoid Hold and Wait on physical devices)"
      },
      {
        "key": "D",
        "text": "Killing the youngest process"
      }
    ],
    "answer": "C",
    "explanation": "Spooling (Simultaneous Peripheral Operations On-Line) virtualizes devices. Instead of a process holding a physical printer (Mutual Exclusion), it writes to a disk file (spool). The daemon handles the printer, removing the deadlock condition regarding exclusive hardware access."
  },
  {
    "id": 52,
    "question": "The time it takes to move the disk arm to the required cylinder is called:",
    "options": [
      {
        "key": "A",
        "text": "Seek Time"
      },
      {
        "key": "B",
        "text": "Latency"
      },
      {
        "key": "C",
        "text": "Transmission Time"
      },
      {
        "key": "D",
        "text": "Response Time"
      }
    ],
    "answer": "A",
    "explanation": "Seek time is the mechanical delay required for the disk arm (actuator) to move the read/write head from its current position to the cylinder containing the desired data."
  },
  {
    "id": 53,
    "question": "Copy-on-Write allows parent and child processes to share pages until:",
    "options": [
      {
        "key": "A",
        "text": "The child terminates."
      },
      {
        "key": "B",
        "text": "The parent terminates."
      },
      {
        "key": "C",
        "text": "Either process modifies a shared page."
      },
      {
        "key": "D",
        "text": "The time quantum expires."
      }
    ],
    "answer": "C",
    "explanation": "Copy-on-Write (COW) is an optimization where parent and child share physical pages after a fork(). The OS only creates a copy of a page when one of the processes tries to write to it, conserving memory."
  },
  {
    "id": 54,
    "question": "If a system has a 32-bit logical address and a 4KB page size, the page table will have approximately how many entries?",
    "options": [
      {
        "key": "A",
        "text": "32,000"
      },
      {
        "key": "B",
        "text": "64,000"
      },
      {
        "key": "C",
        "text": "1 Million ($2^{20}$)"
      },
      {
        "key": "D",
        "text": "4 Billion"
      }
    ],
    "answer": "C",
    "explanation": "The number of entries = Total Logical Address Space / Page Size. Calculation: 2^32 / 2^12 = 2^20. 2^20 is approximately 1,000,000 entries (specifically 1,048,576)."
  },
  {
    "id": 55,
    "question": "Which of the following is true about FAT (File Allocation Table)?",
    "options": [
      {
        "key": "A",
        "text": "It uses contiguous allocation."
      },
      {
        "key": "B",
        "text": "It is a variation of linked allocation where links are stored in a separate table."
      },
      {
        "key": "C",
        "text": "It supports no random access."
      },
      {
        "key": "D",
        "text": "It is an inode-based system."
      }
    ],
    "answer": "B",
    "explanation": "The FAT system pulls the pointers out of the data blocks and stores them in a dedicated table at the beginning of the volume. This allows the OS to follow the chain without reading every data block, enabling faster access."
  },
  {
    "id": 56,
    "question": "The Protection Domain determines:",
    "options": [
      {
        "key": "A",
        "text": "The priority of the process."
      },
      {
        "key": "B",
        "text": "The set of access rights a process has."
      },
      {
        "key": "C",
        "text": "The memory space of the process."
      },
      {
        "key": "D",
        "text": "The CPU time allocated."
      }
    ],
    "answer": "B",
    "explanation": "A Protection Domain defines the boundaries within which a process operates. It specifies strictly which objects (files, hardware) the process can access and what operations (read, write, execute) it can perform on them."
  },
  {
    "id": 57,
    "question": "Swap space management is primarily concerned with:",
    "options": [
      {
        "key": "A",
        "text": "Managing RAM."
      },
      {
        "key": "B",
        "text": "Managing disk space used for moving processes out of main memory."
      },
      {
        "key": "C",
        "text": "Managing CPU registers."
      },
      {
        "key": "D",
        "text": "Managing cache memory."
      }
    ],
    "answer": "B",
    "explanation": "Swap space is a reserved area on the disk (or a file). When physical RAM is full, the OS moves inactive pages or entire processes to this swap space to free up RAM for active tasks."
  },
  {
    "id": 58,
    "question": "Which algorithm handles the \"Belady’s Anomaly\"?",
    "options": [
      {
        "key": "A",
        "text": "FIFO"
      },
      {
        "key": "B",
        "text": "Stack-based algorithms (like LRU)"
      },
      {
        "key": "C",
        "text": "Second-Chance"
      },
      {
        "key": "D",
        "text": "Random"
      }
    ],
    "answer": "B",
    "explanation": "Stack algorithms satisfy the inclusion property: the set of pages in memory with N frames is always a subset of the pages in memory with N+1 frames. This mathematical property prevents Belady's Anomaly."
  },
  {
    "id": 59,
    "question": "A Relocatable Code implies that:",
    "options": [
      {
        "key": "A",
        "text": "Physical addresses are generated at compile time."
      },
      {
        "key": "B",
        "text": "Base registers are used to calculate physical addresses at runtime."
      },
      {
        "key": "C",
        "text": "The code cannot be moved once loaded."
      },
      {
        "key": "D",
        "text": "It uses absolute addressing."
      }
    ],
    "answer": "B",
    "explanation": "Relocatable code uses relative addressing. At runtime, the hardware adds the value of a relocation (base) register to every logical address generated to find the actual physical memory location."
  },
  {
    "id": 60,
    "question": "The Wait and Signal operations of a semaphore are atomic. This means:",
    "options": [
      {
        "key": "A",
        "text": "They are executed very quickly."
      },
      {
        "key": "B",
        "text": "They cannot be called recursively."
      },
      {
        "key": "C",
        "text": "They cannot be interrupted."
      },
      {
        "key": "D",
        "text": "They are implemented in user space."
      }
    ],
    "answer": "C",
    "explanation": "Atomicity is crucial for semaphores. If a process is executing a Wait or Signal operation, no other process can interrupt it or access the semaphore variable until the operation is fully complete, preventing race conditions."
  },
  {
    "id": 61,
    "question": "Index Allocation (like inodes) solves the external fragmentation of Contiguous allocation and the poor direct access of Linked allocation by:",
    "options": [
      {
        "key": "A",
        "text": "Using a FAT."
      },
      {
        "key": "B",
        "text": "Bringing all pointers together into an index block."
      },
      {
        "key": "C",
        "text": "Using variable partition sizes."
      },
      {
        "key": "D",
        "text": "Compressing the file."
      }
    ],
    "answer": "B",
    "explanation": "Indexed allocation gives each file an index block containing pointers to all its data blocks. This supports direct access (calculating the offset in the index block) and eliminates external fragmentation (blocks can be anywhere)."
  },
  {
    "id": 62,
    "question": "If you want to ensure no process starves on a disk queue, you should avoid:",
    "options": [
      {
        "key": "A",
        "text": "FCFS"
      },
      {
        "key": "B",
        "text": "SCAN"
      },
      {
        "key": "C",
        "text": "SSTF"
      },
      {
        "key": "D",
        "text": "C-LOOK"
      }
    ],
    "answer": "C",
    "explanation": "SSTF creates a risk of starvation. If requests continue to arrive near the current head position, the disk arm will stay there to minimize seek time, ignoring requests at the other end of the disk indefinitely."
  },
  {
    "id": 63,
    "question": "Which condition must hold for a Critical Section?",
    "options": [
      {
        "key": "A",
        "text": "Mutual Exclusion"
      },
      {
        "key": "B",
        "text": "Preemption"
      },
      {
        "key": "C",
        "text": "Deadlock"
      },
      {
        "key": "D",
        "text": "Latency"
      }
    ],
    "answer": "A",
    "explanation": "For a Critical Section to function correctly, Mutual Exclusion is mandatory. It ensures that if process P is executing in its critical section, no other process can be executing in their corresponding critical sections."
  },
  {
    "id": 64,
    "question": "Dynamic Linking is most useful for:",
    "options": [
      {
        "key": "A",
        "text": "Embedded systems."
      },
      {
        "key": "B",
        "text": "Shared libraries (like .dll or .so files)."
      },
      {
        "key": "C",
        "text": "Real-time systems."
      },
      {
        "key": "D",
        "text": "Boot loaders."
      }
    ],
    "answer": "B",
    "explanation": "Dynamic linking keeps libraries separate on disk. Multiple programs can link to the same library file at runtime. This saves disk space and RAM, as one copy of the library code is shared in memory."
  },
  {
    "id": 65,
    "question": "A \"page fault\" is an interrupt raised by:",
    "options": [
      {
        "key": "A",
        "text": "The Operating System."
      },
      {
        "key": "B",
        "text": "The Hardware (MMU)."
      },
      {
        "key": "C",
        "text": "The User Program."
      },
      {
        "key": "D",
        "text": "The Disk Drive."
      }
    ],
    "answer": "B",
    "explanation": "A page fault is a hardware exception (trap). When the MMU tries to translate an address and finds the \"Valid/Invalid\" bit set to Invalid, it raises a hardware interrupt to tell the OS to fetch the page from disk."
  },
  {
    "id": 66,
    "question": "Monitor is a high-level synchronization construct that:",
    "options": [
      {
        "key": "A",
        "text": "Uses spinlocks internally."
      },
      {
        "key": "B",
        "text": "Ensures only one process can be active within the monitor at a time."
      },
      {
        "key": "C",
        "text": "Is faster than semaphores."
      },
      {
        "key": "D",
        "text": "Causes deadlocks easily."
      }
    ],
    "answer": "B",
    "explanation": "A Monitor is a high-level language construct. The compiler automatically injects the mutual exclusion logic, ensuring only one thread can execute code inside the monitor instance at any moment."
  },
  {
    "id": 67,
    "question": "What is the main purpose of the SSTF algorithm?",
    "options": [
      {
        "key": "A",
        "text": "To minimize total head movement."
      },
      {
        "key": "B",
        "text": "To ensure fairness."
      },
      {
        "key": "C",
        "text": "To service the oldest request first."
      },
      {
        "key": "D",
        "text": "To minimize CPU usage."
      }
    ],
    "answer": "A",
    "explanation": "The primary goal of Shortest Seek Time First (SSTF) is performance optimization. By always choosing the closest request, it reduces the total distance the disk arm travels, thereby reducing the average seek time."
  },
  {
    "id": 68,
    "question": "In RAID, redundancy is used to improve:",
    "options": [
      {
        "key": "A",
        "text": "Speed."
      },
      {
        "key": "B",
        "text": "Reliability."
      },
      {
        "key": "C",
        "text": "Capacity."
      },
      {
        "key": "D",
        "text": "Formatting time."
      }
    ],
    "answer": "B",
    "explanation": "RAID (Redundant Array of Independent Disks) levels like RAID 1 (Mirroring) or RAID 5 (Parity) use redundancy to ensure that if a single disk fails, the data can be recovered or operations can continue without data loss."
  },
  {
    "id": 69,
    "question": "Which file attribute is NOT typically stored in the file control block (inode)?",
    "options": [
      {
        "key": "A",
        "text": "File size."
      },
      {
        "key": "B",
        "text": "File owner."
      },
      {
        "key": "C",
        "text": "File content."
      },
      {
        "key": "D",
        "text": "Time of last modification."
      }
    ],
    "answer": "C",
    "explanation": "The File Control Block (FCB or inode) stores metadata about the file (permissions, owner, size, timestamps, and pointers to data blocks). It does not store the actual data/content of the file itself."
  },
  {
    "id": 70,
    "question": "Pure Code (Reentrant Code) is:",
    "options": [
      {
        "key": "A",
        "text": "Code that modifies itself."
      },
      {
        "key": "B",
        "text": "Code that can be shared by multiple processes simultaneously without modification."
      },
      {
        "key": "C",
        "text": "Code that has no variables."
      },
      {
        "key": "D",
        "text": "Code written in Assembly."
      }
    ],
    "answer": "B",
    "explanation": "Pure (Reentrant) code does not change during execution; it holds no static data. This allows multiple processes to execute the same memory block of code safely while keeping their own separate data/stack areas."
  },
  {
    "id": 71,
    "question": "Look and C-Look are optimizations of SCAN that:",
    "options": [
      {
        "key": "A",
        "text": "Don't go to the physical end of the disk, only to the furthest request."
      },
      {
        "key": "B",
        "text": "Move faster."
      },
      {
        "key": "C",
        "text": "Use caching."
      },
      {
        "key": "D",
        "text": "Prioritize reads over writes."
      }
    ],
    "answer": "A",
    "explanation": "Standard SCAN goes from end-to-end even if the last request is at 90. LOOK and C-LOOK optimize this by reversing direction immediately after serving the last request at 90, saving idle travel time."
  },
  {
    "id": 72,
    "question": "Preemption is required for which type of scheduling?",
    "options": [
      {
        "key": "A",
        "text": "FCFS"
      },
      {
        "key": "B",
        "text": "Round Robin"
      },
      {
        "key": "C",
        "text": "Non-preemptive SJF"
      },
      {
        "key": "D",
        "text": "Cooperative Scheduling"
      }
    ],
    "answer": "B",
    "explanation": "Round Robin is inherently preemptive. It relies on a timer interrupt (time quantum). When the time is up, the OS forcibly takes the CPU away from the current process and gives it to the next one."
  },
  {
    "id": 73,
    "question": "Peterson's Solution is a software-based solution for:",
    "options": [
      {
        "key": "A",
        "text": "Deadlock recovery."
      },
      {
        "key": "B",
        "text": "Critical Section problem for 2 processes."
      },
      {
        "key": "C",
        "text": "Memory fragmentation."
      },
      {
        "key": "D",
        "text": "Disk scheduling."
      }
    ],
    "answer": "B",
    "explanation": "Peterson’s Solution is a classic algorithmic solution that provides Mutual Exclusion, Progress, and Bounded Waiting for two processes using two shared variables (turn and flag) without special hardware instructions."
  },
  {
    "id": 74,
    "question": "If the page size is too small:",
    "options": [
      {
        "key": "A",
        "text": "The page table becomes very large."
      },
      {
        "key": "B",
        "text": "Internal fragmentation increases."
      },
      {
        "key": "C",
        "text": "Access time decreases."
      },
      {
        "key": "D",
        "text": "Thrashing is eliminated."
      }
    ],
    "answer": "A",
    "explanation": "If pages are tiny (e.g., 256 bytes), a large memory space will be divided into millions of pages. This requires a massive page table to map them all, wasting memory on management overhead."
  },
  {
    "id": 75,
    "question": "Safe Sequence <P1,P2,P3> implies:",
    "options": [
      {
        "key": "A",
        "text": "P1 must finish before P2 starts."
      },
      {
        "key": "B",
        "text": "System can allocate resources to P1, then wait for P1 to finish/release, then satisfy P2, and so on."
      },
      {
        "key": "C",
        "text": "P3 holds the most resources."
      },
      {
        "key": "D",
        "text": "There is no circular wait."
      }
    ],
    "answer": "B",
    "explanation": "A safe sequence ensures that P1 can finish with currently available resources. Once P1 finishes, it returns its resources, which—added to the available pool—are enough to let P2 finish, and so on."
  },
  {
    "id": 76,
    "question": "Contiguous Memory Allocation suffers primarily from:",
    "options": [
      {
        "key": "A",
        "text": "Internal Fragmentation."
      },
      {
        "key": "B",
        "text": "External Fragmentation."
      },
      {
        "key": "C",
        "text": "Page Faults."
      },
      {
        "key": "D",
        "text": "Slow Access Time."
      }
    ],
    "answer": "B",
    "explanation": "Contiguous allocation requires a continuous block of memory. As processes are loaded and removed, free memory becomes broken into small, non-contiguous holes that are too small to be useful individually."
  },
  {
    "id": 77,
    "question": "Which structure allows a large logical address space to be mapped to a smaller physical memory?",
    "options": [
      {
        "key": "A",
        "text": "Overlays."
      },
      {
        "key": "B",
        "text": "Segmentation."
      },
      {
        "key": "C",
        "text": "Virtual Memory (Paging)."
      },
      {
        "key": "D",
        "text": "DMA."
      }
    ],
    "answer": "C",
    "explanation": "Virtual memory separates logical memory from physical memory. It allows a program to have a logical address space much larger than actual RAM by only keeping the currently needed pages in physical memory."
  },
  {
    "id": 78,
    "question": "A Race Condition occurs when:",
    "options": [
      {
        "key": "A",
        "text": "Two processes read the same data."
      },
      {
        "key": "B",
        "text": "The outcome of execution depends on the specific order in which access takes place."
      },
      {
        "key": "C",
        "text": "One process is faster than the other."
      },
      {
        "key": "D",
        "text": "A process dies unexpectedly."
      }
    ],
    "answer": "B",
    "explanation": "A race condition happens when multiple processes access and manipulate shared data concurrently. The final value of the data depends on the luck of the scheduling order, leading to bugs."
  },
  {
    "id": 79,
    "question": "In Capability Lists:",
    "options": [
      {
        "key": "A",
        "text": "Each process has a list of objects it can access."
      },
      {
        "key": "B",
        "text": "Each object has a list of processes that can access it."
      },
      {
        "key": "C",
        "text": "There is a central matrix."
      },
      {
        "key": "D",
        "text": "Access is public."
      }
    ],
    "answer": "A",
    "explanation": "In a Capability List implementation of the Access Matrix, the matrix is decomposed by row. Each process (domain) carries a list of \"capabilities\" (like tickets or keys) for the objects it is allowed to touch."
  },
  {
    "id": 80,
    "question": "Memory Mapped I/O means:",
    "options": [
      {
        "key": "A",
        "text": "I/O devices have their own dedicated bus."
      },
      {
        "key": "B",
        "text": "Device control registers are mapped into the memory address space of the processor."
      },
      {
        "key": "C",
        "text": "I/O is handled only by the kernel."
      },
      {
        "key": "D",
        "text": "Files are always loaded into RAM."
      }
    ],
    "answer": "B",
    "explanation": "Memory Mapped I/O allows the CPU to control hardware devices using standard memory instructions (like Load/Store) by assigning specific memory addresses to device registers, rather than using special I/O instructions."
  },
  {
    "id": 81,
    "question": "Counting Semaphores are initialized to:",
    "options": [
      {
        "key": "A",
        "text": "0"
      },
      {
        "key": "B",
        "text": "1"
      },
      {
        "key": "C",
        "text": "The number of available resources."
      },
      {
        "key": "D",
        "text": "-1"
      }
    ],
    "answer": "C",
    "explanation": "A counting semaphore is used to track available instances of a resource. It is initialized to the total count (e.g., 5 printers). Wait decrements the count; Signal increments it."
  },
  {
    "id": 82,
    "question": "The seek time is the time to move the arm, and rotational latency is the time for the sector to rotate. The sum of these plus transfer time is:",
    "options": [
      {
        "key": "A",
        "text": "Throughput."
      },
      {
        "key": "B",
        "text": "Disk Access Time."
      },
      {
        "key": "C",
        "text": "Bus Latency."
      },
      {
        "key": "D",
        "text": "Response Time."
      }
    ],
    "answer": "B",
    "explanation": "The total time to satisfy a disk request is the sum of getting to the right place (Seek Time + Rotational Latency) and the actual time to read the data (Transfer Time)."
  },
  {
    "id": 83,
    "question": "Which is a technique to avoid External Fragmentation without using paging?",
    "options": [
      {
        "key": "A",
        "text": "Compaction"
      },
      {
        "key": "B",
        "text": "Swapping"
      },
      {
        "key": "C",
        "text": "Zoning"
      },
      {
        "key": "D",
        "text": "Formatting"
      }
    ],
    "answer": "A",
    "explanation": "Compaction is the only way to fix external fragmentation in contiguous systems without changing the architecture. It physically moves memory contents to push all free space to one end, creating one large usable block."
  },
  {
    "id": 84,
    "question": "FCFS disk scheduling is generally:",
    "options": [
      {
        "key": "A",
        "text": "Fair but performs poorly."
      },
      {
        "key": "B",
        "text": "Unfair and performs poorly."
      },
      {
        "key": "C",
        "text": "Optimal."
      },
      {
        "key": "D",
        "text": "Complex to implement."
      }
    ],
    "answer": "A",
    "explanation": "FCFS is fair because it strictly follows the order of arrival (no starvation). However, it does not optimize for seek time, leading to \"wild\" swings of the disk arm and slow performance."
  },
  {
    "id": 85,
    "question": "In a system using RR Scheduling, if a process is I/O bound, it will:",
    "options": [
      {
        "key": "A",
        "text": "Use its full time quantum."
      },
      {
        "key": "B",
        "text": "Relinquish the CPU voluntarily before the quantum expires."
      },
      {
        "key": "C",
        "text": "Be moved to a lower priority queue."
      },
      {
        "key": "D",
        "text": "Cause a deadlock."
      }
    ],
    "answer": "B",
    "explanation": "I/O bound processes spend little time computing. They will issue an I/O request quickly and block themselves (give up the CPU) long before their time quantum runs out, leading to short CPU bursts."
  },
  {
    "id": 86,
    "question": "Safe State is ______ condition for deadlock freedom.",
    "options": [
      {
        "key": "A",
        "text": "A Necessary"
      },
      {
        "key": "B",
        "text": "A Sufficient"
      },
      {
        "key": "C",
        "text": "Not a related"
      },
      {
        "key": "D",
        "text": "An equivalent"
      }
    ],
    "answer": "B",
    "explanation": "If a system is in a Safe State, it is guaranteed that no deadlock exists. Therefore, being in a safe state is sufficient to prove the system is deadlock-free."
  },
  {
    "id": 87,
    "question": "Which of the following allows a file to be distributed across different disks?",
    "options": [
      {
        "key": "A",
        "text": "Linked Allocation"
      },
      {
        "key": "B",
        "text": "Contiguous Allocation"
      },
      {
        "key": "C",
        "text": "Striping (RAID)"
      },
      {
        "key": "D",
        "text": "Inode"
      }
    ],
    "answer": "C",
    "explanation": "Disk striping divides data into blocks and spreads them across multiple physical disks (RAID 0). This allows parallel reading/writing, improving performance, and creating a file system larger than a single disk."
  },
  {
    "id": 88,
    "question": "If a process attempts to access a page that is not in its address space (invalid reference), the OS handles this by:",
    "options": [
      {
        "key": "A",
        "text": "Loading the page."
      },
      {
        "key": "B",
        "text": "Ignoring it."
      },
      {
        "key": "C",
        "text": "Terminating the process (Segmentation Fault)."
      },
      {
        "key": "D",
        "text": "Waiting."
      }
    ],
    "answer": "C",
    "explanation": "If a process tries to access a logical address that is not mapped in its page table (not part of its allocated address space), it is an illegal access. The OS traps this error and terminates the process."
  },
  {
    "id": 89,
    "question": "Working Set is defined as the set of pages referenced in the most recent:",
    "options": [
      {
        "key": "A",
        "text": "Time quantum."
      },
      {
        "key": "B",
        "text": "Delta ($\\Delta$) time units."
      },
      {
        "key": "C",
        "text": "Process lifetime."
      },
      {
        "key": "D",
        "text": "Critical section."
      }
    ],
    "answer": "B",
    "explanation": "The Working Set model looks at the most recent Delta time references. The set of unique pages accessed during this time window is considered the process's current \"Working Set.\""
  },
  {
    "id": 90,
    "question": "Base and Limit registers define:",
    "options": [
      {
        "key": "A",
        "text": "The logical address space of a process."
      },
      {
        "key": "B",
        "text": "The physical memory size."
      },
      {
        "key": "C",
        "text": "The disk capacity."
      },
      {
        "key": "D",
        "text": "The page table size."
      }
    ],
    "answer": "A",
    "explanation": "In contiguous allocation, the Base register holds the smallest physical address, and the Limit register holds the size of the range. Together, they define and protect the process's logical address space."
  },
  {
    "id": 91,
    "question": "Bit Vector is a common method for:",
    "options": [
      {
        "key": "A",
        "text": "Page replacement."
      },
      {
        "key": "B",
        "text": "Free space management on disk."
      },
      {
        "key": "C",
        "text": "Deadlock detection."
      },
      {
        "key": "D",
        "text": "Process scheduling."
      }
    ],
    "answer": "B",
    "explanation": "A Bit Vector (or Bit Map) is a compact way to track free disk blocks. Each block is represented by 1 bit (0 for allocated, 1 for free). This allows the OS to quickly find free blocks."
  },
  {
    "id": 92,
    "question": "The Dispatcher is the module that:",
    "options": [
      {
        "key": "A",
        "text": "Selects the process to run."
      },
      {
        "key": "B",
        "text": "Gives control of the CPU to the process selected by the short-term scheduler."
      },
      {
        "key": "C",
        "text": "Moves processes to disk."
      },
      {
        "key": "D",
        "text": "Handles interrupts."
      }
    ],
    "answer": "B",
    "explanation": "The Scheduler decides who runs next. The Dispatcher is the mechanism that actually switches to that process (performing context switch, switching to user mode, and jumping to the instruction)."
  },
  {
    "id": 93,
    "question": "Priority Inversion can be solved by:",
    "options": [
      {
        "key": "A",
        "text": "Disabling interrupts."
      },
      {
        "key": "B",
        "text": "Priority Inheritance Protocol."
      },
      {
        "key": "C",
        "text": "Killing the low-priority process."
      },
      {
        "key": "D",
        "text": "Using FCFS."
      }
    ],
    "answer": "B",
    "explanation": "Priority Inversion happens when a low-priority task holds a lock needed by a high-priority task. Priority Inheritance temporarily raises the priority of the lock-holder to that of the waiter, so it can finish and release the lock faster."
  },
  {
    "id": 94,
    "question": "Spinlocks are useful in:",
    "options": [
      {
        "key": "A",
        "text": "Single-processor systems."
      },
      {
        "key": "B",
        "text": "Multi-processor systems (for short waits)."
      },
      {
        "key": "C",
        "text": "I/O bound processes."
      },
      {
        "key": "D",
        "text": "Long critical sections."
      }
    ],
    "answer": "B",
    "explanation": "Spinlocks cause the CPU to \"busy wait\". On a single core, this wastes time. On multicore systems, if the wait is short, spinning is cheaper than the overhead of a context switch."
  },
  {
    "id": 95,
    "question": "In Indexed Allocation, the max file size depends on:",
    "options": [
      {
        "key": "A",
        "text": "Disk size."
      },
      {
        "key": "B",
        "text": "The number of pointers in the index block."
      },
      {
        "key": "C",
        "text": "RAM size."
      },
      {
        "key": "D",
        "text": "The file name."
      }
    ],
    "answer": "B",
    "explanation": "In standard Indexed Allocation, the file size is limited by how many block pointers fit inside the single index block."
  },
  {
    "id": 96,
    "question": "Which is false about threads?",
    "options": [
      {
        "key": "A",
        "text": "They share the code section."
      },
      {
        "key": "B",
        "text": "They share open files."
      },
      {
        "key": "C",
        "text": "They share the stack."
      },
      {
        "key": "D",
        "text": "They share data section."
      }
    ],
    "answer": "C",
    "explanation": "Threads within the same process share the code segment, data segment, and OS resources. However, each thread must have its own stack to manage its own function calls and local variables."
  },
  {
    "id": 97,
    "question": "The Bootstrap program is typically stored in:",
    "options": [
      {
        "key": "A",
        "text": "RAM."
      },
      {
        "key": "B",
        "text": "ROM or EEPROM."
      },
      {
        "key": "C",
        "text": "Hard Disk (Sector 100)."
      },
      {
        "key": "D",
        "text": "Cache."
      }
    ],
    "answer": "B",
    "explanation": "The bootstrap program runs when the computer is first turned on. Since RAM is volatile, this initial code must be stored in non-volatile memory like ROM or firmware (BIOS/UEFI)."
  },
  {
    "id": 98,
    "question": "Shortest Job First (SJF) is optimal in terms of:",
    "options": [
      {
        "key": "A",
        "text": "Throughput."
      },
      {
        "key": "B",
        "text": "Minimum average waiting time."
      },
      {
        "key": "C",
        "text": "Fairness."
      },
      {
        "key": "D",
        "text": "CPU utilization."
      }
    ],
    "answer": "B",
    "explanation": "SJF is mathematically proven to provide the lowest possible average waiting time for a given set of processes because it clears the queue of short tasks quickly."
  },
  {
    "id": 99,
    "question": "A system has 4 processes and 3 resource types. To ensure deadlock freedom using the Banker's algorithm, we must check the:",
    "options": [
      {
        "key": "A",
        "text": "Need Matrix vs Available Vector."
      },
      {
        "key": "B",
        "text": "Allocation Matrix vs Max Matrix."
      },
      {
        "key": "C",
        "text": "Hold count."
      },
      {
        "key": "D",
        "text": "Wait queue length."
      }
    ],
    "answer": "A",
    "explanation": "The Banker's Algorithm checks safety by comparing the Need (Max - Allocation) of a process against the currently Available resources. If Available >= Need, the process can theoretically finish."
  },
  {
    "id": 100,
    "question": "File System consistency checks (like fsck or chkdsk) compare:",
    "options": [
      {
        "key": "A",
        "text": "Data in memory vs Disk."
      },
      {
        "key": "B",
        "text": "Directory structure vs the actual blocks allocated on disk."
      },
      {
        "key": "C",
        "text": "User permissions."
      },
      {
        "key": "D",
        "text": "File names."
      }
    ],
    "answer": "B",
    "explanation": "Consistency checkers ensure the file system metadata is valid. They check if a block is marked as \"used\" in the free-space list but not claimed by any file in the directory structure."
  }
]